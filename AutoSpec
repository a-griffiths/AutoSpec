#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AutoSpec: Automated Datacube Spectrum Extractor
@author: Alex Griffiths
v 1.1.2
20-09-2018
"""
# Import dependencies.
from __future__ import absolute_import, division, print_function

from mpdaf.obj import Cube, Image
from mpdaf.sdetect import Source
import matplotlib.pyplot as plt
import astropy.units as u
import seaborn as sns
import numpy as np
import warnings
import mpdaf
import time
import sys
import os

# Set up seaborn plot.
sns.set_style("ticks")
sns.set_context("paper")

# Software info.
SOFTWARE = 'AutoSpec'
VERSION = 'v.1.1.2'
AUTHOR = 'Alex Griffiths'


# Main function that does the bulk of the work.
def create_source(ID, ra, dec, size, ref):
    """Create source object based on input datacube and images.

    Appends images and subcube to the source and extracts object spectra.

    Parameters
    ----------
    ID : int
        ID of the source
    ra : double
        Right ascension in degrees
    dec : double
        Declination in degrees
    size : float
        The size to extract. It corresponds to the size along the delta axis
        and the image is square. If empty get value from parameter file.
    ref : Str
        If mode is img, ref should be name of reference image for spectrum
        weighting. If mode is aper, should be the size of aperture to extract
        the spectrum from.

    """
    # Set up the working mode and reference spectrum tag.
    ref = ref.replace('.fits', '').upper()
    if ref == '':
        ext_mode = 'IMG'
        refspec = 'MUSE_WHITE'
    elif ref.replace('.', '').isdigit() is False:
        ext_mode = 'IMG'
        refspec = ref
    elif ref.replace('.', '').isdigit() is True:
        ext_mode = 'APER'
        refspec = 'MUSE_APER_%.1f' % float(ref)
    elif ref not in imgs.keys():
        print('Reference not in images or apertures, using white light.')
        ext_mode = 'IMG'
        refspec = 'MUSE_WHITE'

    # This creates the source object (see MPDAF for more details).
    s = Source.from_data(ID=ID, ra=ra, dec=dec, extras=extra,
                         origin=(params.ORIG_FROM, params.ORIG_FROMV,
                                 params.ORIG_CUBE, params.ORIGN_CUBEV))

    # Add subcube, create white image and add any additional images.
    s = add_data(s, size)

    # Add SExtractor segmentation maps and create masks.
    s, seg = create_masks(s)
    mask = 'MASK_'+params.OBJ_MASK.upper()
    ref_mask = 'MASK_'+params.OBJ_MASK.upper()

    # If the user sets mask to intersection and it is empty, default to the
    # union mask instead.
    if np.sum(s.images[mask].data.data) == 0:
        mask = 'MASK_UNION'
        ref_mask = 'MASK_UNION'

    # If aperture used as reference, create mask at set aperture size.
    if ext_mode == 'APER':
        temp = s.images['MUSE_WHITE'].copy()
        pxsz = temp.get_step(unit=u.arcsec)[0]
        cntr = [temp.shape[0]/2, temp.shape[0]/2]
        rds = float(ref)/pxsz

        temp.mask_region(center=cntr, radius=rds, unit_center=None,
                         unit_radius=None, inside=False)

        s.images['MASK_APER_%.1f_SKY' % float(ref)] = \
            temp.new_from_obj(temp, data=temp.mask*1)
        s.images['MASK_APER_%.1f_OBJ' % float(ref)] = \
            temp.new_from_obj(temp, data=abs((temp.mask*1)-1))

        ref_mask = 'MASK_APER_%.1f_OBJ' % float(ref)

    # Extract all spectra set by user.
    tags = [i for i in s.images.keys() if 'SEG_' not in i and 'MASK_' not in i]
    aps = params.APER if isinstance(params.APER, tuple) else [params.APER]

    s.extract_spectra(s.cubes['MUSE'], obj_mask=mask,
                      sky_mask='MASK_SKY', skysub=params.SKY_SUB,
                      tags_to_try=tags, apertures=aps)

    # Set up naming convention based on if the user has sky-subtraction set.
    if params.SKY_SUB is True:
        ssfx = '_SKYSUB'
    else:
        ssfx = ''

    # No need to subtract continuum if we're not going to cross-correlate.
    if params.XCOR is True and params.CONT_SUB is True:
        # Set up naming conventions.
        csfx = '_CONTSUB'
        # Perform continuum subtraction on reference spectrum.
        s.spectra[refspec+csfx+ssfx] = s.spectra[refspec+ssfx] - \
            s.spectra[refspec+ssfx].poly_spec(params.CONT_POLY)
        # Perform continuum subtraction on datacube.
        s.add_cube(continuum_subtraction(s, params.CONT_POLY), 'MUSE'+csfx)

    else:
        csfx = ''

    if params.XCOR is True:
        # Extract a cross-correlate spectrum without continuum subtraction...
        s = cross_correlate(s, refspec, '', ssfx, ref_mask)
        # ...and with continuum subtraction.
        s = cross_correlate(s, refspec, csfx, ssfx, ref_mask)

    # If user wants them, plots are created and output here.
    if params.PLOTS is True:
        make_plots(s, ID, refspec, ssfx)

    # Output file is cleaned if the user wishes.
    s = clean_output(s, refspec, csfx, ssfx)

    return s


def add_data(src, size):
    """Add additional images and segmentation maps to the source object

    Parameters
    ----------
    src : mpdaf.sdetect.source.Source
        Input source object
    size : float
        The size to extract. It corresponds to the size along the delta axis
        and the image is square.

    """
    src.add_cube(cube, 'MUSE', size=size)
    src.add_white_image(cube, size=size)

    # Add images.
    for key in imgs:
        src.add_image(imgs[key], name=key)

    # Add extra segmentation maps.
    for key in smaps:
        src.add_image(smaps[key], name='SEG_'+key)

    return src


def create_masks(src):
    """Create segmentation maps and masks

    Parameters
    ----------
    src : mpdaf.sdetect.source.Source
        Input source object

    """
    src.add_seg_images(del_sex=False)
    seg = [i for i in src.images.keys() if 'SEG_' in i]
    # Do not use the white light image not set.
    if params.USE_IMGS is False:
        seg.remove('SEG_MUSE_WHITE')
        for key in imgs:
            seg.remove('SEG_'+key)
    src.find_sky_mask(seg)
    src.find_union_mask(seg)
    # Check if any maps are empty before creating intersection mask.
    for key in seg:
        if np.sum(src.images[key].data.data) == 0:
            seg.remove(key)
    src.find_intersection_mask(seg)

    return src, seg


def continuum_subtraction(src, poly):
    """Perform continuum subtraction from the MUSE subcube

    Parameters
    ----------
    src : mpdaf.sdetect.source.Source
        Input source object
    poly : int
        Order of the polynomial for continuum estimation

    """
    cube = src.cubes['MUSE']
    nl = cube.shape
    x = np.arange(nl[0])
    data = cube.data.filled(0).reshape(nl[0], -1)

    res = np.polynomial.polynomial.polyfit(x, data, deg=poly)
    res2 = np.polynomial.polynomial.polyval(x, res, tensor=True).transpose()
    res3 = np.subtract(data, res2)
    res4 = np.reshape(res3, [nl[0], nl[1], nl[2]])

    csub = cube.new_from_obj(cube, data=res4, var=cube.var)

    return csub


def cross_correlate(src, refspec, csfx, ssfx, mask):
    """Create cross-correlation image against reference spectrum

    Parameters
    ----------
    src : mpdaf.sdetect.source.Source
        Input source object
    refspec : Str
        String representing reference spectra for cross correlation
    csfx : Str
        Continuum subtraction suffix string
    ssfx : Str
        Sky subtraction suffix string
    mask : Str
        Object mask used for initial spectrum extraction

    """
    ref = refspec+csfx+ssfx
    cubeName = 'MUSE'+csfx
    refImg = src.images['MUSE_WHITE']

    scube = src.cubes[cubeName]
    rspec = src.spectra[ref]

    # Create cross correlation image.
    xc = rspec * scube
    xc = (xc.data.data).sum(axis=0)

    # Add image to source.
    src.images['CROSS_CORRELATION'+csfx] = refImg.new_from_obj(refImg, data=xc)

    # Extract masked cross-correlation spectrum.
    src.extract_spectra(src.cubes['MUSE'], obj_mask=mask,
                        sky_mask='MASK_SKY', skysub=params.SKY_SUB,
                        tags_to_try=['CROSS_CORRELATION'+csfx])

    return src


def make_plots(src, ID, refspec, ssfx):
    """Create and output plots

    Parameters
    ----------
    src : mpdaf.sdetect.source.Source
        Input source object
    ID : int
        ID of the source
    refspec : Str
        String representing reference spectra for cross correlation
    ssfx : Str
        Sky subtraction suffix string

    """
    # Set colourmap.
    plt.rcParams['image.cmap'] = str(params.CMAP)

    # Make source subdirectory.
    t_path = params.OUTPUT+'/images/'+str(ID)
    if not os.path.exists(t_path):
        os.makedirs(t_path)

    # Plot images and segmentation maps and save file.
    key = [i for i in src.images.keys() if 'MASK' not in i]
    key = [i for i in key if 'CROSS_CORRELATION' not in i]
    k1 = [i for i in key if 'SEG' not in i]
    k2 = [i for i in key if 'SEG' in i]
    c = len(k1)
    r = np.ceil(len(key)/len(k1))
    plt.figure(figsize=(c*2.5, r*2.5))
    for i, j in enumerate(k1):
        plt.subplot(r, c, i+1)
        src.images[j].plot(title=j)
        plt.subplot(r, c, i+1+len(k1))
        src.images['SEG_'+j].plot(title='SEG_'+j)
        k2.remove('SEG_'+j)
    for i, j in enumerate(k2):
        plt.subplot(r, c, i+1+2*len(k1))
        src.images[j].plot(title=j)
    plt.tight_layout()
    plt.savefig(t_path+'/%s_IMAGES.jpg' % ID)

    # Plot masks and save file.
    key = [i for i in src.images.keys() if 'MASK' in i]
    plt.figure(figsize=(len(key)*2.5, len(key)))
    for i, j in enumerate(key):
        plt.subplot(1, len(key), i+1)
        src.images[j].plot(title=j)
    plt.tight_layout()
    plt.savefig(t_path+'/%s_MASKS.jpg' % ID)

    # Plot spectra and save file.
    key = [i for i in src.spectra.keys() if 'CROSS_CORRELATION' in i]
    key.insert(0, refspec+ssfx)
    plt.figure(figsize=(10, len(key)*2.5))
    for i, j in enumerate(key):
        plt.subplot(len(key), 1, i+1)
        src.spectra[j].plot(title=j)
    plt.tight_layout()
    plt.savefig(t_path+'/%s_SPECTRA.jpg' % ID)

    # Plot and save cross correlation images.
    if params.XCOR is True:
        key = [i for i in src.images.keys() if 'CROSS_CORRELATION' in i]
        plt.figure(figsize=(len(key)*4, 4))
        for i, j in enumerate(key):
            plt.subplot(1, len(key), i+1)
            src.images[j].plot(title=j)
        plt.tight_layout()
        plt.savefig(t_path+'/%s_XCOR.jpg' % ID)


def clean_output(src, refspec, csfx, ssfx):
    """Clean the output based on user defined parameters

    Parameters
    ----------
    src : mpdaf.sdetect.source.Source
        Input source object
    refspec : Str
        String representing reference spectra for cross correlation
    csfx : Str
        Continuum subtraction suffix string
    ssfx : Str
        Sky subtraction suffix string

    """
    # Remove images.
    if params.OUT_IMG is False:
        print('Removing images')
        for key in imgs:
            del src.images[key]
        del src.images['MUSE_WHITE']

    # Remove image segmentation maps.
    if params.OUT_SEG is False:
        print('Removing segmentation maps')
        rm = [i for i in src.images.keys() if 'SEG_' in i]
        for n in rm:
            del src.images[n]

    # Remove object mask, sky mask.
    if params.OUT_MASK is False:
        print('Removing masks')
        rm = [i for i in src.images.keys() if 'MASK_' in i]
        for n in rm:
            del src.images[n]

    if params.OUT_XCOR is False:
        print('Removing cross-correlation')
        rm = [i for i in src.images.keys() if 'CROSS_CORRELATION' in i]
        for n in rm:
            del src.images[n]

    # Remove additional spectra.
    if params.OUT_SPEC is False:
        print('Removing additional spectra')
        rm = [i for i in src.spectra.keys() if 'CROSS_CORRELATION' not in i]
        rm = [i for i in rm if refspec+csfx+ssfx not in i]
        for n in rm:
            del src.spectra[n]

    # Remove subcubes.
    if params.OUT_SUB is False:
        print('Removing subcubes')
        src.cubes.clear()

    return src


# Create progress bar to show catalog progress.
def print_progress(ID, iteration, total, bar_length=100):
    """
    Call in a loop to create terminal progress bar

    Parameters
    ----------
    ID : int
        id of current interation
    iteration : int
        current iteration
    total : int
        total iterations
    suffix : Str
        suffix string
    decimals : int
        number of decimals in percent complete
    bar_length : int
        character length of bar

    """
    str_format = '{0:.1f}'
    percents = str_format.format(100*(iteration/float(total)))
    filled_length = int(round(bar_length*iteration/float(total)))
    bar = '█'*filled_length+'-'*(bar_length-filled_length)

    sys.stdout.write('\nSource  :  %s/%s (ID: %s) \n'
                     'Progress: |%s| %s%s Complete\n\n'
                     % (iteration, total, ID, bar, percents, '%'))
    sys.stdout.flush()


def main():

    # Set up global variables.
    global cube, params, imgs, smaps, extra

    # Create log file.
    if not os.path.exists('logs'):
        os.makedirs('logs')

    log = open(time.strftime('logs/%d%b%Y_%H%M%S.log'), 'w')
    log.write('# Log file: '+time.strftime("%c")+'\n')
    log.write('# '+str(SOFTWARE)+': '+str(VERSION)+'\n\n')

    # Set current working directory.
    cwd = os.getcwd()+'/'

    # First check that the parameter file exists and is named correctly.
    print('Getting parameter file...')
    try:
        sys.path.append(str(cwd))
        import param as params
    except Exception:
        log.write('Error: No parameter file found')
        log.close()
        raise ImportError('No parameter file found, please ensure file name'
                          ' is param.py and located in the working directory.')

    # Sometimes if the datacube has some odd headers in, astropy gives off
    # a load of warnings that dominate the output, if this is the case the
    # user can choose to ignore them.
    if params.WARNINGS is True:
        warnings.filterwarnings('default')
    else:
        warnings.filterwarnings('ignore')
        mpdaf.log.setup_logging(level='INFO')

    # Check that the defined catalogue file exists and import it.
    print('Loading catalog...')
    try:
        cat = np.genfromtxt(params.CATALOG, dtype=str)
    except Exception:
        log.write('Error: No catalog file found')
        log.close()
        raise ImportError('No catalog file ('+str(params.CATALOG)+') found.')

    # Check the datacube exists and import it.
    print('Importing datacube...')
    try:
        if params.DATA_EXT is not ():
            cube = Cube(params.DATACUBE, ext=params.DATA_EXT)
        else:
            cube = Cube(params.DATACUBE)
    except Exception:
        log.write('Error: No datacube file found')
        log.close()
        raise ImportError('No datacube file ('+str(params.DATACUBE)+') found.')

    # Import any additional images defined in the parameter file.
    imgs = {}
    if params.IMG != '':
        print('Importing and aligning images...')
        ref_white = cube.sum(axis=0)
        itmp = params.IMG if isinstance(params.IMG, tuple) else [params.IMG]
        for i in itmp:
            imgs[i.replace('.fits', '').upper()] = \
                Image(i).align_with_image(ref_white)

    # Import any additional segmentation maps defined in the parameter file.
    smaps = {}
    if params.SEG != '':
        print('Importing segmentation maps...')
        stmp = params.SEG if isinstance(params.SEG, tuple) else [params.SEG]
        for i in stmp:
            smaps[i.replace('.fits', '').upper()] = Image(i)

    # If all files load successfully, create output directory folder.
    print('Creating output directories...')
    file_path = params.OUTPUT
    if not os.path.exists(file_path):
        os.makedirs(file_path)

    # Create images folder if plots are to be created.
    if params.PLOTS is True:
        if not os.path.exists(file_path+'/images'):
            os.makedirs(file_path+'/images')

    # Define additional headers to be stored in fits.
    extra = {'EXT': (SOFTWARE, 'extraction software'),
             'EXT_V': (VERSION, 'version of the extraction software'),
             'AUTH': (AUTHOR, 'author of extraction software')}

    # Run code for a single object catalog.
    if cat.size <= 5:
        print('Extracting single source '+cat[0]+'...\n')
        try:
            ts = time.time()
            # Extract using settings in parameter file.
            if params.MODE.upper() == 'PARAM' or cat.size == 3:
                S = create_source(ID=int(cat[0]),
                                  ra=float(cat[1]),
                                  dec=float(cat[2]),
                                  size=float(params.SIZE),
                                  ref=str(params.REF))
            # Extract using parameters defined in the catalog.
            else:
                S = create_source(ID=int(cat[0]),
                                  ra=float(cat[1]),
                                  dec=float(cat[2]),
                                  size=float(cat[3]),
                                  ref=str(cat[4]))
            S.write(file_path+'/'+params.PRE_OUT+'%s.fits' % cat[0])
            rt = time.time()-ts
            log.write('%s: Extracted Successfully in %.2fs\n' % (cat[0], rt))
            del S
        except Exception as e:
            print('Error: '+str(e))
            log.write(cat[0] + ': Error 1, '+str(e)+'\n')
            pass

    # Run code over multi-object catalog.
    else:
        print('Extracting sources...\n')
        # Find catalog length for progress bar.
        length = len(cat)
        for n, m in enumerate(cat):
            try:
                ts = time.time()
                # Extract using settings in parameter file.
                if params.MODE.upper() == 'PARAM' or m.size == 3:
                    S = create_source(ID=int(m[0]),
                                      ra=float(m[1]),
                                      dec=float(m[2]),
                                      size=float(params.SIZE),
                                      ref=str(params.REF))
                # Extract using parameters defined in the catalog.
                else:
                    S = create_source(ID=int(m[0]),
                                      ra=float(m[1]),
                                      dec=float(m[2]),
                                      size=float(m[3]),
                                      ref=str(m[4]))
                S.write(file_path+'/'+params.PRE_OUT+'%s.fits' % m[0])
                rt = time.time()-ts
                log.write('%s: Extracted Successfully in %.2fs\n' % (m[0], rt))
                del S
            except Exception as e:
                print('Error : Source '+m[0]+' '+str(e), end='\r')
                log.write(m[0] + ': Error, '+str(e)+'\n')
                pass
            # Show current progress.
            print_progress(m[0], n+1, length, bar_length=50)

    # close the log file.
    log.close()


# Run the code.
if __name__ == '__main__':
    main()
